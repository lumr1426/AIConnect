{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from modules.utils import load_yaml, save_yaml, get_logger\n", "from modules.earlystoppers import EarlyStopper\n", "from modules.recorders import Recorder\n", "from modules.datasets import SplitDataset, CustomDataset\n", "from modules.optimizers import get_optimizer\n", "from modules.metrics import get_metric\n", "from modules.losses import get_loss\n", "from modules.trainer import Trainer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from models.utils import get_model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from torch.utils.data import DataLoader\n", "import torch, wandb\n", "import wandb"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from datetime import datetime, timezone, timedelta\n", "import numpy as np\n", "import os, shutil, copy, random"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import warnings\n", "warnings.filterwarnings('ignore')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Root Directory"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["PROJECT_DIR = os.path.dirname(__file__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load config"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["config_path = os.path.join(PROJECT_DIR, 'config', 'train_config.yaml')\n", "config = load_yaml(config_path)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train Serial"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["kst = timezone(timedelta(hours=9))\n", "train_serial = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Recorder Directory"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if config['LOGGER']['debug']:\n", "    RECORDER_DIR = os.path.join(PROJECT_DIR, 'results', 'train', 'debug')\n", "    # remove the record directory if it exists even though directory not empty\n", "    if os.path.exists(RECORDER_DIR): shutil.rmtree(RECORDER_DIR)\n", "else:\n", "    RECORDER_DIR = os.path.join(PROJECT_DIR, 'results', 'train', train_serial)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["os.makedirs(RECORDER_DIR, exist_ok=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Wandb Setting"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if config['LOGGER']['wandb']:\n", "    run = wandb.init(project='fake_or_real',\n", "                     name=train_serial,\n", "                     config=config,)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Data Directory"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["DATA_DIR = config['DIRECTORY']['dataset']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Seed"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["torch.manual_seed(config['TRAINER']['seed'])\n", "torch.backends.cudnn.deterministic = True\n", "torch.backends.cudnn.benchmark = False\n", "np.random.seed(config['TRAINER']['seed'])\n", "random.seed(config['TRAINER']['seed'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["GPU"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n", "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(config['TRAINER']['gpu'])\n", "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    '''\n", "    Set Logger\n", "    '''\n", "    logger = get_logger(name='train', dir_=RECORDER_DIR, stream=False)\n", "    logger.info(f\"Set Logger {RECORDER_DIR}\")\n", "    \n", "    '''\n", "    Load Data\n", "    '''\n", "    # Dataset\n", "    X_train, X_val, Y_train, Y_val = SplitDataset(img_dir = DATA_DIR,\n", "                 val_size = config['DATASET']['val_size'],\n", "                 seed = config['TRAINER']['seed'],)\n", "        \n", "    train_dataset = CustomDataset(X = X_train, y = Y_train)\n", "    val_dataset = CustomDataset(X = X_val, y = Y_val)\n\n", "    # DataLoader\n", "    train_dataloader = DataLoader(dataset = train_dataset,\n", "                                  batch_size = config['DATALOADER']['batch_size'],\n", "                                  num_workers = config['DATALOADER']['num_workers'],\n", "                                  shuffle = config['DATALOADER']['shuffle'],\n", "                                  pin_memory = config['DATALOADER']['pin_memory'],\n", "                                  drop_last = config['DATALOADER']['drop_last'])\n", "    \n", "    val_dataloader = DataLoader(dataset = val_dataset,\n", "                                batch_size = config['DATALOADER']['batch_size'],\n", "                                num_workers = config['DATALOADER']['num_workers'], \n", "                                shuffle = False,\n", "                                pin_memory = config['DATALOADER']['pin_memory'],\n", "                                drop_last = config['DATALOADER']['drop_last'])\n", "    logger.info(f\"Load data, train:{len(train_dataset)} val:{len(val_dataset)}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["    \n<br>\n", "    Set model<br>\n", "  \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # Load model\n", "    model_name = config['TRAINER']['model']\n", "    model_args = config['MODEL'][model_name]\n", "    model = get_model(model_name = model_name, model_args = model_args).to(device)\n", "    \n", "    '''\n", "    Set trainer\n", "    '''\n", "    # Optimizer\n", "    optimizer = get_optimizer(optimizer_name=config['TRAINER']['optimizer'])\n", "    optimizer = optimizer(params=model.parameters(),lr=config['TRAINER']['learning_rate'])\n\n", "    # Loss\n", "    loss = get_loss(loss_name=config['TRAINER']['loss'])\n", "    \n", "    # Metric\n", "    metrics = {metric_name: get_metric(metric_name) for metric_name in config['TRAINER']['metric']}\n", "    \n", "    # Early stoppper\n", "    early_stopper = EarlyStopper(patience=config['TRAINER']['early_stopping_patience'],\n", "                                mode=config['TRAINER']['early_stopping_mode'],\n", "                                logger=logger)\n\n", "    # AMP\n", "    if config['TRAINER']['amp'] == True:\n", "        from apex import amp\n", "        model, optimizer = amp.initialize(model, optimizer, opt_level='O1')\n", "    \n", "    # Trainer\n", "    trainer = Trainer(model=model,\n", "                      optimizer=optimizer,\n", "                      loss=loss,\n", "                      metrics=metrics,\n", "                      device=device,\n", "                      logger=logger,\n", "                      amp=amp if config['TRAINER']['amp'] else None,\n", "                      interval=config['LOGGER']['logging_interval'])\n", "    \n", "    '''\n", "    Logger\n", "    '''\n", "    # Recorder\n", "    recorder = Recorder(record_dir=RECORDER_DIR,\n", "                        model=model,\n", "                        optimizer=optimizer,\n", "                        scheduler=None,\n", "                        amp=amp if config['TRAINER']['amp'] else None,\n", "                        logger=logger)\n\n", "    # Save train config\n", "    save_yaml(os.path.join(RECORDER_DIR, 'train_config.yml'), config)\n", "    '''\n", "    TRAIN\n", "    '''\n", "    # Train\n", "    n_epochs = config['TRAINER']['n_epochs']\n", "    for epoch_index in range(n_epochs):\n\n", "        # Set Recorder row\n", "        row_dict = dict()\n", "        row_dict['epoch_index'] = epoch_index\n", "        row_dict['train_serial'] = train_serial\n", "        \"\"\"\n", "        Train\n", "        \"\"\"\n", "        print(f\"Train {epoch_index}/{n_epochs}\")\n", "        logger.info(f\"--Train {epoch_index}/{n_epochs}\")\n", "        trainer.train(dataloader=train_dataloader, epoch_index=epoch_index, mode='train')\n", "        \n", "        row_dict['train_loss'] = trainer.loss_mean\n", "        row_dict['train_elapsed_time'] = trainer.elapsed_time \n", "        \n", "        for metric_str, score in trainer.score_dict.items():\n", "            row_dict[f\"train_{metric_str}\"] = score\n", "        trainer.clear_history()\n", "        \n", "        \"\"\"\n", "        Validation\n", "        \"\"\"\n", "        print(f\"Val {epoch_index}/{n_epochs}\")\n", "        logger.info(f\"--Val {epoch_index}/{n_epochs}\")  \n", "        trainer.train(dataloader=val_dataloader, epoch_index=epoch_index, mode='val')\n", "        \n", "        row_dict['val_loss'] = trainer.loss_mean\n", "        row_dict['val_elapsed_time'] = trainer.elapsed_time \n", "        \n", "        for metric_str, score in trainer.score_dict.items():\n", "            row_dict[f\"val_{metric_str}\"] = score\n", "        trainer.clear_history()\n", "        \n", "        \"\"\"\n", "        Record\n", "        \"\"\"\n", "        # Log results on the local\n", "        recorder.add_row(row_dict)\n", "        recorder.save_plot(config['LOGGER']['plot'])\n", "        \n", "        # Log results on the online (wandb)\n", "        if config[\"LOGGER\"][\"wandb\"]:\n", "            wandb.log(row_dict)\n", "        \n", "        \"\"\"\n", "        Early stopper\n", "        \"\"\"\n", "        early_stopping_target = config['TRAINER']['early_stopping_target']\n", "        early_stopper.check_early_stopping(loss=row_dict[early_stopping_target])\n", "        if (early_stopper.patience_counter == 0) or (epoch_index == n_epochs-1):\n", "            recorder.save_weight(epoch=epoch_index)\n", "            best_row_dict = copy.deepcopy(row_dict)\n", "        \n", "        if early_stopper.stop == True:\n", "            logger.info(f\"Eearly stopped, counter {early_stopper.patience_counter}/{config['TRAINER']['early_stopping_patience']}\")\n", "            "]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}